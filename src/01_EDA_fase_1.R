#Script lecutra y clasificación de tweets

library(tidyverse)
library(tidytext)
library(igraph)
library(ggraph)
library(wordcloud)
library(magrittr)
library(tm)
library(stringi)
library(reshape2)
library(topicmodels)
library(widyr)
library(stringr)
library(forcats)
library(plotly)
library(arulesViz)
library(arules)


tweets_raw <- read_csv("datos/tweets_cuentascdmx.csv")

#stopwords
stop_words_es <- read_csv("helpers/stopwords_espanol.csv")

#primer vistazo todos los tweets
stop_words <- data.frame(word = c(c(stop_words_es$text, "xd", 
                                  "https", "rt", "t.co", "quiero", 
                                  "solo", "asi", "hoy", "dia", "jajaja",
                                  "q"),
                                  c(tm::stopwords(kind = "en")))) %>% 
  mutate(word = stri_trans_general(word, id = "Latin-ASCII"))

#Se crean categrías 
tweets_deporte <- tweets_raw %>% 
  mutate(tweet_text = tweet_text %>% 
           tolower() %>% 
           str_replace("@", "zzz") %>% 
           stri_trans_general(id = "Latin-ASCII"),
         tipo = ifelse(str_detect(tweet_text, "pumas"), "deporte",
                ifelse(str_detect(tweet_text, "futbol"), "deporte", 
                ifelse(str_detect(tweet_text, "nfl"), "deporte",
                ifelse(str_detect(tweet_text, "espn"), "deporte",
                ifelse(str_detect(tweet_text, "sports"), "deporte",
                ifelse(str_detect(tweet_text, "puma"), "deporte","nada")))))))
    
                                                
tweets_sismo <- tweets_deporte %>% 
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "sismo"), "sismo",tipo))


tweets_debate <- tweets_sismo %>% 
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "debate"), "debate", tipo))

tweets_discriminacion <- tweets_debate %>% 
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "discriminacion"), "discriminacion", 
                       ifelse(str_detect(tweet_text, "discriminar"), "discriminacion", tipo)))

tweets_epn <- tweets_discriminacion %>% 
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "epn"), "epn", tipo))

tweets_cumpleanos <- tweets_epn %>% 
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "cumpleanos"), "cumple", tipo))

tweet_genero <- tweets_cumpleanos %>% 
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text,"luchona"), "genero", 
                ifelse(str_detect(tweet_text,"vieja loca"), "genero",
                ifelse(str_detect(tweet_text,"es de nina"), "genero",
                ifelse(str_detect(tweet_text,"como nina"), "genero",
                ifelse(str_detect(tweet_text,"como los hombre"), "genero",
                ifelse(str_detect(tweet_text,"feminazi"), "genero",
                ifelse(str_detect(tweet_text,"para que tienes hijos"), "genero", "nada"))))))))

tweet_orientacion <- tweet_genero %>% 
  filter(tipo != "genero") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text,"lesbiana"), "orientacion", 
                ifelse(str_detect(tweet_text,"machorra"), "orientacion",
                ifelse(str_detect(tweet_text,"maricon"), "orientacion",
                ifelse(str_detect(tweet_text,"puto"), "orientacion",
                ifelse(str_detect(tweet_text,"joto"), "orientacion",
                ifelse(str_detect(tweet_text,"punal"), "orientacion",
                ifelse(str_detect(tweet_text,"lencha"), "orientacion", 
                ifelse(str_detect(tweet_text, "Le gusta el arroz con popote"), "orientacion",
                       "nada")))))))))
                                  

tweet_ideoligia <- tweet_orientacion %>% 
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "chairo"), "idelogia", 
                ifelse(str_detect(tweet_text, "derechairo"), "ideologia",
                ifelse(str_detect(tweet_text, "chairos"), "idelogia", "nada"))))

tweet_apariencia <- tweet_ideoligia %>%
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "naco"), "apariencia", 
                ifelse(str_detect(tweet_text, "jodido"), "apariencia", 
                ifelse(str_detect(tweet_text, "iztapalacra"), "apariencia",
                ifelse(str_detect(tweet_text, "chacha"), "apariencia",
                ifelse(str_detect(tweet_text, "pinch fresa"), "apariencia", 
                ifelse(str_detect(tweet_text, "pinch negro"), "apariencia",
                ifelse(str_detect(tweet_text, "pinche grodo"), "apariencia",
                ifelse(str_detect(tweet_text, "pinche indio"), "apariencia",
                ifelse(str_detect(tweet_text, "pinche pobre"), "apariencia",
                ifelse(str_detect(tweet_text, "guerito"), "apariencia", tipo )))))))))))

tweet_religion <- tweet_apariencia %>% 
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "testiculos de jehova"), "religion",
                ifelse(str_detect(tweet_text, "judio"), "religion",
                ifelse(str_detect(tweet_text, "testigos de Jehova"), "religion",tipo))))

tweet_edad <- tweet_religion %>%
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "pinche viejo"), "edad",
                ifelse(str_detect(tweet_text, "pinche nino"), "edad",
                ifelse(str_detect(tweet_text, "pareces nino chiquito"), "edad",
                ifelse(str_detect(tweet_text, "es chavo"), "edad",
                ifelse(str_detect(tweet_text, "chavorruco"), "edad",
                ifelse(str_detect(tweet_text, "chavoruco"), "edad",
                ifelse(str_detect(tweet_text, "nini"), "edad", tipo))))))))

tweet_discapacidad <- tweet_edad %>%
  filter(tipo == "nada") %>% 
  mutate(tipo = ifelse(str_detect(tweet_text, "nino teleton"), "discapacidad",
                ifelse(str_detect(tweet_text, "discapacitado"), "discapacidad", "nada")))



#palabras que mas se repiten 

tweetsk <- tweets_raw %>% 
  select(tweet_text) %>% 
  mutate(tweet_text = tweet_text %>% 
           stri_trans_general(id = "Latin-ASCII") %>% 
           str_replace("@", "zzz")) %>% 
  unnest_tokens(word, tweet_text) %>%
  filter(!str_detect(word,"zzz"),
         !word %in% stop_words$word) %>% 
  count(word, sort = TRUE)

#topic model: En lugar de crear groups manualmente aplicamos topic modeling
#Topic modeling es un método para la calsifiación no supervisada

tweets_tm <- tweets_raw %>% 
  select(user_id, tweet_text) %>% 
  mutate(tweet_text = tweet_text %>% 
           stri_trans_general(id = "Latin-ASCII") %>% 
           str_replace("@", "zzz")) %>% 
  unnest_tokens(word, tweet_text) %>%
  filter(!str_detect(word,"zzz"),
         !word %in% stop_words$word) %>% 
  count(user_id, word, sort = TRUE)

chapters_dtm <- tweets_tm %>%
  cast_dtm(user_id, word, n)

#Ajustamos el topic modelo con LDA
#La asignación latente de Dirichlet (LDA) es un método particularmente popular
#para ajustar un modelo de temas.

chapters_lda <- LDA(chapters_dtm, k = 5, control = list(seed = 1234))
chapters_lda

chapter_topics <- tidy(chapters_lda, matrix = "beta")
chapter_topics

top_terms <- chapter_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms

#5 grupos 
top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

#topic model bi
# ahora creamos topicos por bigramas

tweets_tm <- tweets_raw %>% 
  select(user_id, tweet_text) %>% 
  mutate(tweet_text = tweet_text %>% 
           stri_trans_general(id = "Latin-ASCII") %>% 
           str_replace("@", "zzz")) %>% 
  unnest_tokens(word, tweet_text, token = "ngrams", n = 2) %>%
  separate(word, c("word1", "word2"), sep = " ") %>% 
  filter(!str_detect(word1,"zzz"),
         !str_detect(word2,"zzz"),
         !word1 %in% stop_words$word,
         !word2 %in% stop_words$word) %>% 
  unite("word", c("word1", "word2"), sep = " ") %>%
  count(user_id, word, sort = TRUE)

chapters_dtm <- tweets_tm %>%
  cast_dtm(user_id, word, n)

chapters_lda <- LDA(chapters_dtm, k = 5, control = list(seed = 1234))
chapters_lda

chapter_topics <- tidy(chapters_lda, matrix = "beta")
chapter_topics


top_terms <- chapter_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()


### Visualización de una red de bigramas con ggraph

tweets_tm <- tweets_raw %>% 
  select(user_id, tweet_text) %>% 
  mutate(tweet_text = tweet_text %>% 
           stri_trans_general(id = "Latin-ASCII") %>% 
           str_replace("@", "zzz")) %>% 
  unnest_tokens(word, tweet_text, token = "ngrams", n = 2) %>%
  separate(word, c("word1", "word2"), sep = " ") %>% 
  filter(!str_detect(word1,"zzz"),
         !str_detect(word2,"zzz"),
         !word1 %in% stop_words$word,
         !word2 %in% stop_words$word) %>% 
  select(-user_id) %>% 
  count(word1, word2, sort = TRUE)


bigram_graph <- tweets_tm %>%
  filter(n > 80) %>%
  graph_from_data_frame()

bigram_graph

set.seed(2017)

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)


